# 7. 大数定律 (Law of Large Numbers)

本章讨论概率论中一组重要的极限定理——大数定律。它们描述了在大量重复试验中，样本均值收敛于总体期望的现象，是连接理论概率与统计推断的桥梁。

## 7.1 切比雪夫不等式 (Chebyshev's Inequality)

切比雪夫不等式给出了随机变量偏离其期望值的概率的一个上界，这个界不依赖于具体的分布形式，只需要期望和方差存在。

设随机变量 X 具有期望 E(X) = μ 和方差 D(X) = σ² (0 < σ² < +∞)。则对于任意正数 ε > 0，有：
\[ P(|X - \mu| \geq \epsilon) \leq \frac{\sigma^2}{\epsilon^2} \]
或者等价地：
\[ P(|X - \mu| < \epsilon) \geq 1 - \frac{\sigma^2}{\epsilon^2} \]

切比雪夫不等式的意义在于它对任何分布都成立，但通常这个界比较宽松。

## 7.2 弱大数定律 (Weak Law of Large Numbers, WLLN)

弱大数定律表明，当试验次数足够大时，样本均值依概率收敛于总体期望。

**定理 (切比雪夫弱大数定律)**：设 X<sub>1</sub>, X<sub>2</sub>, ..., X<sub>n</sub>, ... 是一列相互独立、具有相同期望 E(X<sub>i</sub>) = μ 和相同方差 D(X<sub>i</sub>) = σ² < +∞ 的随机变量序列。令 S<sub>n</sub> = Σ<sub>i=1</sub><sup>n</sup> X<sub>i</sub> 为前 n 个随机变量之和， \( \bar{X}_n = S_n / n \) 为样本均值。则对于任意 ε > 0，有：
\[ \lim_{n \to \infty} P(|\bar{X}_n - \mu| < \epsilon) = 1 \]
或者等价地：
\[ \lim_{n \to \infty} P(|\bar{X}_n - \mu| \geq \epsilon) = 0 \]
这表示样本均值 \( \bar{X}_n \) 依概率收敛于 μ，记作 \( \bar{X}_n \xrightarrow{P} \mu \)。

**定理 (伯努利弱大数定律)**：设 n<sub>A</sub> 是 n 次独立重复伯努利试验中事件 A 发生的次数，p 是事件 A 在每次试验中发生的概率。则对于任意 ε > 0，有：
\[ \lim_{n \to \infty} P\left(\left| \frac{n_A}{n} - p \right| < \epsilon\right) = 1 \]
伯努利大数定律说明了频率的稳定性，即当试验次数 n 很大时，事件的频率 n<sub>A</sub>/n 会非常接近其概率 p。

## 7.3 强大数定律 (Strong Law of Large Numbers, SLLN)

强大数定律比弱大数定律有更强的收敛性，它表明样本均值几乎必然收敛于总体期望。

**定理 (柯尔莫哥洛夫强大数定律)**：设 X<sub>1</sub>, X<sub>2</sub>, ..., X<sub>n</sub>, ... 是一列相互独立同分布 (i.i.d.) 的随机变量序列，且期望 E(X<sub>i</sub>) = μ 存在。令 \( \bar{X}_n = (X_1 + ... + X_n) / n \)。则：
\[ P\left( \lim_{n \to \infty} \bar{X}_n = \mu \right) = 1 \]
这表示样本均值 \( \bar{X}_n \) 几乎处处收敛 (Almost Surely Converge) 或以概率1收敛于 μ，记作 \( \bar{X}_n \xrightarrow{a.s.} \mu \)。

**WLLN 与 SLLN 的区别**：
*   **收敛模式**：WLLN 是依概率收敛，SLLN 是几乎必然收敛。几乎必然收敛强于依概率收敛。
*   **含义**：
    *   WLLN：对于一个很大的固定的 n，样本均值偏离总体期望很远的概率很小。
    *   SLLN：对于一个特定的样本序列 (试验结果序列)，当 n 趋于无穷时，样本均值最终会等于总体期望，除非发生了一个概率为0的例外事件。
*   **条件**：SLLN 通常需要更强的条件（如独立同分布且期望存在，或者其他更复杂的条件），而 WLLN 的条件相对宽松一些（如切比雪夫 WLLN 只需要独立、同期望、同方差且方差有限）。

## 7.4 大数定律的应用 (Applications of LLN)

大数定律是概率论与数理统计之间重要的理论基石。
*   **理论基础**：
    *   为用频率近似概率提供了理论依据 (伯努利大数定律)。
    *   解释了为什么在大量重复试验中，随机事件的平均结果趋于稳定。
*   **统计推断**：
    *   参数估计：用样本均值估计总体期望 (矩估计法的基础)。
    *   蒙特卡洛方法：通过大量随机抽样来估计复杂问题的数值解，例如计算定积分、求解方程等。
*   **风险管理与保险**：保险公司能够通过大数定律预测赔付总额，从而制定合理的保费。
*   **质量控制**：通过抽样检查来判断整批产品的质量。

本章节是大数定律的初步介绍，更深入的讨论和不同版本的大数定律（如辛钦大数定律等）将在后续课程或高级概率论中涉及。 