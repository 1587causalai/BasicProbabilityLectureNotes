\documentclass[UTF8]{beamer} % UTF8 option for ctex is often preferred
\usepackage{ctex}       % 支持中文
\usepackage{amsmath}    % 数学公式
\usepackage{amssymb}    % For math symbols like \mathbb
% \usepackage{graphicx} % If you plan to add images
% \usepackage{booktabs} % For better tables, if needed

% \usetheme{default} % Original theme
\usetheme{Madrid}    % A popular, clean theme with a sidebar
\usecolortheme{dolphin} % A pleasant color theme

% Optional: Remove navigation symbols at the bottom if the sidebar is sufficient
% \setbeamertemplate{navigation symbols}{}

\title{第七讲 大数定律}
\subtitle{概率论的基石：从理论到应用} % Optional: Add a subtitle
\author{龚鹤扬}
\institute{上海芯梯科技有限公司} % Standard field for institute
\date{\today}

\begin{document}

\frame{\titlepage}

% Optional: Add a table of contents slide
\begin{frame}{本讲纲要}
    \tableofcontents
\end{frame}

\section{引言}
\begin{frame}{引言：大数定律的直观与重要性}
    \begin{itemize}
        \item 本章讨论概率论中一组核心的极限定理——\alert{大数定律}。
        \pause
        \item 描述了在大量重复独立试验中，事件发生的\alert{频率}如何逼近其\alert{概率}，或者\alert{样本均值}如何收敛于\alert{总体期望}的现象。
        \pause
        \item 是连接 \alert{理论概率} 与 \alert{统计推断} 的关键桥梁。
        \pause
        \item 为许多统计方法的合理性提供了坚实的理论基础。
    \end{itemize}
\end{frame}

\section{切比雪夫不等式}
\begin{frame}{7.1 切比雪夫不等式 (Chebyshev's Inequality)}
    \begin{itemize}
        \item 切比雪夫不等式给出了随机变量偏离其期望值的概率的一个\alert{上界}。
        \item 这个界不依赖于随机变量的具体分布形式，只需要其\alert{期望}和\alert{方差}存在且有限。
    \end{itemize}
    \pause
    \begin{block}{切比雪夫不等式}
        设随机变量 X 具有期望 E(X) = μ 和方差 D(X) = σ² (其中 0 < σ² < +∞)。则对于任意正数 ε > 0，有：
        \[ P(|X - \mu| \geq \epsilon) \leq \frac{\sigma^2}{\epsilon^2} \]
        或者等价地：
        \[ P(|X - \mu| < \epsilon) \geq 1 - \frac{\sigma^2}{\epsilon^2} \]
    \end{block}
    \pause
    \textbf{核心特点：}
    \begin{itemize}
        \item \alert{普适性强}：对任何分布都成立（只要期望方差存在）。
        \item \alert{界限较松}：实际应用中，这个上界往往比较宽松。
    \end{itemize}
\end{frame}

\section{弱大数定律}
\begin{frame}{7.2 弱大数定律 (Weak Law of Large Numbers, WLLN)}
    弱大数定律表明，当试验次数足够大时，样本均值\alert{依概率收敛}于总体期望。
    \vspace{0.5cm}

    \begin{block}{定理 (切比雪夫弱大数定律)}
        设 X<sub>1</sub>, X<sub>2</sub>, ..., X<sub>n</sub>, ... 是一列\alert{相互独立}、具有\alert{相同期望} E(X<sub>i</sub>) = μ 和\alert{相同有限方差} D(X<sub>i</sub>) = σ² < +∞ 的随机变量序列。令 S<sub>n</sub> = Σ<sub>i=1</sub><sup>n</sup> X<sub>i</sub> 为前 n 个随机变量之和， \( \bar{X}_n = S_n / n \) 为样本均值。则对于任意 ε > 0，有：
        \[ \lim_{n \to \infty} P(|\bar{X}_n - \mu| < \epsilon) = 1 \]
        或者等价地：
        \[ \lim_{n \to \infty} P(|\bar{X}_n - \mu| \geq \epsilon) = 0 \]
        这表示样本均值 \( \bar{X}_n \) \alert{依概率收敛}于 μ，记作 \( \bar{X}_n \xrightarrow{P} \mu \)。
    \end{block}
\end{frame}

\begin{frame}{伯努利弱大数定律}
    这是切比雪夫弱大数定律在伯努利试验下的一个重要特例。
    \vspace{0.5cm}
    \begin{block}{定理 (伯努利弱大数定律)}
        设 n<sub>A</sub> 是 n 次独立重复伯努利试验中事件 A 发生的次数，p 是事件 A 在每次试验中发生的概率。则对于任意 ε > 0，有：
        \[ \lim_{n \to \infty} P\left(\left| \frac{n_A}{n} - p \right| < \epsilon\right) = 1 \]
        此定律说明了\alert{频率的稳定性}：当试验次数 n 很大时，事件的频率 n<sub>A</sub>/n 会以很高的概率接近其真实的概率 p。
    \end{block}
\end{frame}

\section{强大数定律}
\begin{frame}{7.3 强大数定律 (Strong Law of Large Numbers, SLLN)}
    强大数定律比弱大数定律描述了更强的收敛性，它表明样本均值\alert{几乎必然收敛}于总体期望。
    \vspace{0.5cm}

    \begin{block}{定理 (柯尔莫哥洛夫强大数定律)}
        设 X<sub>1</sub>, X<sub>2</sub>, ..., X<sub>n</sub>, ... 是一列\alert{独立同分布} (i.i.d.) 的随机变量序列，且其共同期望 E(X<sub>i</sub>) = μ \alert{存在} (不要求方差存在或有限)。令 \( \bar{X}_n = (X_1 + ... + X_n) / n \)。则：
        \[ P\left( \lim_{n \to \infty} \bar{X}_n = \mu \right) = 1 \]
        这表示样本均值 \( \bar{X}_n \) \alert{几乎处处收敛} (Almost Surely Converge) 或以概率1收敛于 μ，记作 \( \bar{X}_n \xrightarrow{a.s.} \mu \)。
    \end{block}
    \pause
    \begin{alertblock}{注意}
        SLLN 的条件 (i.i.d. 且期望存在) 与切比雪夫 WLLN 的条件 (独立、同期望、同有限方差) 不同。SLLN 对随机变量的分布限制更少 (不要求方差有限)，但要求同分布。
    \end{alertblock}
\end{frame}

\begin{frame}{WLLN 与 SLLN 的对比}
    \textbf{核心区别}：
    \begin{itemize}
        \item \textbf{收敛模式}：
            \begin{itemize}
                \item WLLN (依概率收敛 \( \xrightarrow{P} \))：
                \[ \forall \epsilon > 0, \lim_{n \to \infty} P(|\bar{X}_n - \mu| \geq \epsilon) = 0 \]
                指对于任意小的 $\epsilon$ 和 $\delta$，总存在 $N$，当 $n > N$ 时，$\bar{X}_n$ 落在 $(\mu-\epsilon, \mu+\epsilon)$ \alert{之外的概率小于 $\delta$}。
                \pause
                \item SLLN (几乎必然收敛 \( \xrightarrow{a.s.} \))：
                \[ P\left( \lim_{n \to \infty} \bar{X}_n = \mu \right) = 1 \]
                指 $\bar{X}_n$ 的序列\alert{几乎必然会收敛到 $\mu$}。也就是说，除了一个概率为零的例外集合，对于每一个样本路径，当 $n \to \infty$ 时，$\bar{X}_n \to \mu$。
            \end{itemize}
        \pause
        \item \textbf{强度}：
            \begin{itemize}
                \item SLLN \alert{更强}。几乎必然收敛 \alert{蕴含} 依概率收敛 (SLLN $\implies$ WLLN)。
            \end{itemize}
        \pause
        \item \textbf{直观解释}：
            \begin{itemize}
                \item WLLN：当 $n$ 很大时，$\bar{X}_n$ \textit{不太可能} 偏离 $\mu$ 太远。
                \item SLLN：当 $n$ 趋于无穷时，$\bar{X}_n$ \textit{最终会等于} $\mu$ (除概率为0的例外)。
            \end{itemize}
        \end{itemize}
\end{frame}

\section{大数定律的应用}
\begin{frame}{7.4 大数定律的应用 (Applications of LLN)}
    大数定律是概率论与数理统计之间重要的理论基石，应用广泛：
    \begin{itemize}
        \item \textbf{理论基础}：
            \begin{itemize}
                \item 为用\alert{频率近似概率}提供了理论依据 (伯努利大数定律)。
                \item 解释了为什么在大量重复试验中，随机事件的\alert{平均结果趋于稳定}。
            \end{itemize}
        \pause
        \item \textbf{统计推断}：
            \begin{itemize}
                \item \alert{参数估计}：用样本均值估计总体期望是矩估计法等方法的基础。
                \item \alert{蒙特卡洛方法}：通过大量随机抽样和计算样本均值来估计复杂问题的数值解 (如积分、期望)。
            \end{itemize}
        \pause
        \item \textbf{实际行业应用}：
            \begin{itemize}
                \item \alert{风险管理与保险}：保险公司能够通过大数定律较准确地预测赔付总额，从而制定合理的保费。
                \item \alert{质量控制}：通过抽样检查产品并计算次品率，来判断整批产品的质量水平。
            \end{itemize}
    \end{itemize}
\end{frame}

\section{总结与展望}
\begin{frame}{总结与展望}
    \begin{block}{本章回顾}
    \begin{itemize}
        \item \textbf{切比雪夫不等式}：提供了概率估计的一个通用（但较宽松）的界。
        \item \textbf{弱大数定律 (WLLN)}：阐述了样本均值依概率收敛于总体期望。
            \begin{itemize}
                \item 切比雪夫WLLN：独立、同期望、同有限方差。
                \item 伯努利WLLN：频率依概率收敛于概率。
            \end{itemize}
        \item \textbf{强大数定律 (SLLN)}：阐述了样本均值几乎必然收敛于总体期望 (更强的收敛形式)。
            \begin{itemize}
                \item 柯尔莫哥洛夫SLLN：独立同分布、期望存在。
            \end{itemize}
        \item 大数定律是频率解释概率、参数估计、蒙特卡洛模拟等众多统计思想的\alert{理论支柱}。
    \end{itemize}
    \end{block}
    \pause
    \begin{alertblock}{展望}
        大数定律有多种形式和更广泛的推广 (如马尔可夫、辛钦大数定律，以及对非独立序列的推广)。
        接下来，我们将学习另一个核心的极限定理——\alert{中心极限定理}，它将告诉我们样本均值围绕总体期望波动的具体分布形态。
    \end{alertblock}
\end{frame}

\end{document}
